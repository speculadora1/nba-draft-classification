{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# read in dataset\n",
    "nba_draftees = pd.read_csv('../data/nba_draftees.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into groups based on draft_season\n",
    "player_data = nba_draftees[nba_draftees['draft_season'] <= 2014]\n",
    "\n",
    "# exclude players who did not meet requirements for model data\n",
    "player_data = player_data[player_data['classification'] != 'Exclude'].reset_index(drop = True)\n",
    "\n",
    "# drop draft_season column\n",
    "player_data.drop(['draft_season'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dummy values for position, conference\n",
    "player_data = pd.get_dummies(player_data, columns=['position', 'conference'])\n",
    "\n",
    "# create target variable\n",
    "target = player_data['classification']\n",
    "\n",
    "# drop data points correlated with existing ones\n",
    "player_data.drop(['assist_percentage', 'block_percentage', 'defensive_rebounds', 'offensive_rebounds',\n",
    "                  'total_rebound_percentage', 'defensive_win_shares', 'offensive_win_shares',\n",
    "                  'win_shares_per_40_minutes', 'effective_field_goal_percentage', 'field_goals',\n",
    "                  'free_throws', 'games_played', 'three_pointers', 'true_shooting_percentage',\n",
    "                  'turnover_percentage', 'two_pointers', 'standing_vertical'], axis = 1, inplace = True)\n",
    "\n",
    "# subset remaining columns with numeric values\n",
    "model_data = player_data.select_dtypes(include=[np.number])\n",
    "\n",
    "# shuffle data to prepare for cross validation\n",
    "model_data = model_data.sample(frac = 1, random_state = 23).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train & test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(model_data, target, random_state = 23)\n",
    "\n",
    "# split categorical data using same train/test split\n",
    "info_cols = player_data.columns.difference(model_data.columns)\n",
    "\n",
    "player_info = player_data[info_cols]\n",
    "\n",
    "train_info, test_info, train_class, test_class = train_test_split(player_info, target, random_state = 23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [20, 30, 40, 50, 60, 70, 80, 90],\n",
    "    'max_features': ['auto', 'sqrt'],\n",
    "    'min_samples_leaf': [2, 3, 4, 5, 6],\n",
    "    'min_samples_split': [2, 4, 6, 8, 10],\n",
    "    'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800]\n",
    "}\n",
    "\n",
    "# Create a based model\n",
    "rfc = RandomForestClassifier(random_state = 23)\n",
    "\n",
    "# Instantiate the grid search model\n",
    "rf_GS = GridSearchCV(estimator = rfc, param_grid = param_grid, \n",
    "                     cv = 5, verbose = 2, n_jobs = -1)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "rf_GS.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the grid search model\n",
    "best_GS = rf_GS.best_estimator_\n",
    "\n",
    "print(f'Grid Search Score: {best_GS.score(X_test, y_test)}')\n",
    "\n",
    "# print best parameters\n",
    "rf_GS.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_raw = pd.DataFrame(zip(test_info['name'], best_GS.predict_proba(X_test), best_GS.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unpack test_raw df\n",
    "player = []\n",
    "bust = []\n",
    "rp = []\n",
    "st = []\n",
    "asg = []\n",
    "tClass = []\n",
    "\n",
    "for index, row in test_raw.iterrows():\n",
    "    player.append(row[0])\n",
    "    asg.append(row[1][0])\n",
    "    st.append(row[1][3])\n",
    "    rp.append(row[1][2])\n",
    "    bust.append(row[1][1])\n",
    "    tClass.append(row[2])\n",
    "\n",
    "test_predictions = pd.DataFrame({'Name': player,\n",
    "                                 'All-Star %': asg,\n",
    "                                 'Starter %': st,\n",
    "                                 'Role Player %': rp,\n",
    "                                 'Bust %': bust,\n",
    "                                 'True Classification': tClass})\n",
    "\n",
    "test_predictions.to_csv('../data/rf_gs.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PythonData] *",
   "language": "python",
   "name": "conda-env-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
